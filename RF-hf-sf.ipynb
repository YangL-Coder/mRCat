{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72426ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from itertools import product\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529271ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047920</td>\n",
       "      <td>-0.044799</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>-0.027684</td>\n",
       "      <td>-0.060108</td>\n",
       "      <td>0.051503</td>\n",
       "      <td>0.074873</td>\n",
       "      <td>0.094912</td>\n",
       "      <td>0.142718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.006833</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063734</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>-0.022348</td>\n",
       "      <td>-0.066921</td>\n",
       "      <td>0.064694</td>\n",
       "      <td>0.101658</td>\n",
       "      <td>0.116233</td>\n",
       "      <td>0.136837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080484</td>\n",
       "      <td>-0.063357</td>\n",
       "      <td>0.037052</td>\n",
       "      <td>-0.023793</td>\n",
       "      <td>-0.052618</td>\n",
       "      <td>0.047666</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>0.100192</td>\n",
       "      <td>0.156532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>-0.043053</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>-0.055099</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>0.093488</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.162534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056244</td>\n",
       "      <td>-0.031527</td>\n",
       "      <td>0.027563</td>\n",
       "      <td>-0.006933</td>\n",
       "      <td>-0.035199</td>\n",
       "      <td>0.053570</td>\n",
       "      <td>0.106644</td>\n",
       "      <td>0.127546</td>\n",
       "      <td>0.129778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071451</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>-0.024152</td>\n",
       "      <td>-0.040399</td>\n",
       "      <td>0.054827</td>\n",
       "      <td>0.108673</td>\n",
       "      <td>0.107649</td>\n",
       "      <td>0.108352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069669</td>\n",
       "      <td>-0.118523</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-0.004282</td>\n",
       "      <td>-0.044469</td>\n",
       "      <td>0.064367</td>\n",
       "      <td>0.085585</td>\n",
       "      <td>0.090057</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>0.018389</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073933</td>\n",
       "      <td>-0.074885</td>\n",
       "      <td>0.044387</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>-0.048722</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>0.119175</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071051</td>\n",
       "      <td>-0.068419</td>\n",
       "      <td>-0.018095</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>-0.081945</td>\n",
       "      <td>0.103257</td>\n",
       "      <td>-0.006743</td>\n",
       "      <td>0.098912</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059454</td>\n",
       "      <td>-0.026457</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.016240</td>\n",
       "      <td>-0.058569</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>0.105976</td>\n",
       "      <td>0.169302</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4662 rows × 840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.008038  0.005472  0.007248  0.007894  0.007398  0.004448  0.000894   \n",
       "1     0.006421  0.004846  0.007124  0.006833  0.007555  0.005529  0.002641   \n",
       "2     0.012833  0.005971  0.006511  0.007626  0.007715  0.005825  0.001119   \n",
       "3     0.013917  0.006805  0.005778  0.013393  0.008006  0.004290  0.000706   \n",
       "4     0.017324  0.006722  0.007164  0.007420  0.007784  0.003431  0.001093   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4657  0.020823  0.006709  0.006760  0.009948  0.007638  0.003582  0.001047   \n",
       "4658  0.002121  0.007038  0.006064  0.003244  0.007038  0.005526  0.002388   \n",
       "4659  0.018389  0.005796  0.007591  0.005788  0.005100  0.006153  0.002046   \n",
       "4660  0.001512  0.001544  0.005322  0.000000  0.003088  0.007880  0.001362   \n",
       "4661  0.006508  0.003946  0.005190  0.002074  0.002492  0.006784  0.002657   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.007232  0.009605  0.007154  ... -0.047920 -0.044799  0.009836   \n",
       "1     0.006684  0.008229  0.006792  ... -0.063734 -0.007245  0.007870   \n",
       "2     0.006599  0.007285  0.005525  ... -0.080484 -0.063357  0.037052   \n",
       "3     0.007448  0.006812  0.002914  ... -0.044457 -0.043053  0.013077   \n",
       "4     0.007214  0.006707  0.006244  ... -0.056244 -0.031527  0.027563   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4657  0.007103  0.007427  0.004873  ... -0.071451 -0.064951  0.026554   \n",
       "4658  0.005519  0.008397  0.006210  ... -0.069669 -0.118523  0.001044   \n",
       "4659  0.007090  0.005993  0.006751  ... -0.073933 -0.074885  0.044387   \n",
       "4660  0.001574  0.003991  0.010899  ... -0.071051 -0.068419 -0.018095   \n",
       "4661  0.002541  0.005190  0.005315  ... -0.059454 -0.026457  0.048786   \n",
       "\n",
       "           762       763       764       765       766       767  label  \n",
       "0    -0.027684 -0.060108  0.051503  0.074873  0.094912  0.142718      1  \n",
       "1    -0.022348 -0.066921  0.064694  0.101658  0.116233  0.136837      1  \n",
       "2    -0.023793 -0.052618  0.047666  0.088847  0.100192  0.156532      1  \n",
       "3    -0.001783 -0.055099  0.052132  0.093488  0.079941  0.162534      1  \n",
       "4    -0.006933 -0.035199  0.053570  0.106644  0.127546  0.129778      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "4657 -0.024152 -0.040399  0.054827  0.108673  0.107649  0.108352      0  \n",
       "4658 -0.004282 -0.044469  0.064367  0.085585  0.090057  0.146606      0  \n",
       "4659 -0.000744 -0.048722 -0.010145  0.098738  0.119175  0.117543      0  \n",
       "4660  0.009988 -0.081945  0.103257 -0.006743  0.098912  0.106491      0  \n",
       "4661  0.016240 -0.058569 -0.023089  0.105976  0.169302  0.109432      0  \n",
       "\n",
       "[4662 rows x 840 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training dataset loading\n",
    "Training_csv_file_path = './data/TrainingSet/mRNA_sublocation_TrainingSet_NC-BERTdata.csv'\n",
    "Training_data= pd.read_csv(Training_csv_file_path)\n",
    "Training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882fb404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053218</td>\n",
       "      <td>-0.046008</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.123339</td>\n",
       "      <td>0.146821</td>\n",
       "      <td>0.165012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060201</td>\n",
       "      <td>-0.053725</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>-0.104437</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.066489</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>0.168197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086440</td>\n",
       "      <td>-0.074154</td>\n",
       "      <td>0.037891</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>-0.048493</td>\n",
       "      <td>0.094847</td>\n",
       "      <td>0.098022</td>\n",
       "      <td>0.145162</td>\n",
       "      <td>0.164766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072469</td>\n",
       "      <td>-0.075094</td>\n",
       "      <td>0.079060</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.033657</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>0.147035</td>\n",
       "      <td>0.143220</td>\n",
       "      <td>0.139921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060701</td>\n",
       "      <td>-0.105159</td>\n",
       "      <td>0.082175</td>\n",
       "      <td>-0.042828</td>\n",
       "      <td>-0.013750</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>0.205573</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083052</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.034709</td>\n",
       "      <td>-0.057688</td>\n",
       "      <td>0.085145</td>\n",
       "      <td>0.059397</td>\n",
       "      <td>0.119146</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050953</td>\n",
       "      <td>-0.018395</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>-0.064337</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.118566</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077407</td>\n",
       "      <td>-0.028342</td>\n",
       "      <td>0.029947</td>\n",
       "      <td>-0.024831</td>\n",
       "      <td>-0.072220</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>0.085262</td>\n",
       "      <td>0.091931</td>\n",
       "      <td>0.144309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115380</td>\n",
       "      <td>-0.046133</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>-0.059596</td>\n",
       "      <td>0.059717</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>0.101675</td>\n",
       "      <td>0.132865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105616</td>\n",
       "      <td>-0.063114</td>\n",
       "      <td>0.069075</td>\n",
       "      <td>0.015171</td>\n",
       "      <td>-0.053736</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.062616</td>\n",
       "      <td>0.111214</td>\n",
       "      <td>0.115066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.011010  0.005166  0.007069  0.009104  0.006584  0.004962  0.000983   \n",
       "1    0.001138  0.002840  0.004449  0.000387  0.005293  0.008433  0.003076   \n",
       "2    0.003841  0.003923  0.006374  0.003134  0.005604  0.007207  0.001879   \n",
       "3    0.004768  0.003772  0.005141  0.003835  0.004800  0.007349  0.002178   \n",
       "4    0.014964  0.005276  0.007248  0.011185  0.005625  0.003709  0.000834   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "513  0.002883  0.003271  0.005074  0.002614  0.003925  0.005676  0.004618   \n",
       "514  0.008520  0.004350  0.004851  0.005622  0.003838  0.005746  0.001919   \n",
       "515  0.003307  0.003241  0.005121  0.002833  0.005537  0.005652  0.001430   \n",
       "516  0.004880  0.002683  0.006275  0.003445  0.004216  0.005869  0.002368   \n",
       "517  0.003484  0.002668  0.004598  0.004885  0.006671  0.004085  0.005101   \n",
       "\n",
       "            7         8         9  ...       759       760       761  \\\n",
       "0    0.006195  0.007331  0.005005  ... -0.053218 -0.046008  0.024874   \n",
       "1    0.004343  0.004783  0.009227  ... -0.060201 -0.053725  0.023453   \n",
       "2    0.005027  0.005505  0.008505  ... -0.086440 -0.074154  0.037891   \n",
       "3    0.004614  0.005968  0.006595  ... -0.072469 -0.075094  0.079060   \n",
       "4    0.006393  0.007677  0.003865  ... -0.060701 -0.105159  0.082175   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "513  0.003668  0.004228  0.007505  ... -0.083052 -0.081839  0.025406   \n",
       "514  0.007434  0.004079  0.004629  ... -0.050953 -0.018395 -0.001208   \n",
       "515  0.006058  0.006633  0.008223  ... -0.077407 -0.028342  0.029947   \n",
       "516  0.002345  0.005615  0.008456  ... -0.115380 -0.046133  0.049324   \n",
       "517  0.003627  0.008430  0.006278  ... -0.105616 -0.063114  0.069075   \n",
       "\n",
       "          762       763       764       765       766       767  label  \n",
       "0   -0.005043 -0.057149  0.022523  0.123339  0.146821  0.165012      1  \n",
       "1    0.007158 -0.104437  0.018186  0.066489  0.168612  0.168197      1  \n",
       "2    0.010463 -0.048493  0.094847  0.098022  0.145162  0.164766      1  \n",
       "3   -0.053585 -0.033657 -0.002991  0.147035  0.143220  0.139921      1  \n",
       "4   -0.042828 -0.013750 -0.040331  0.205573  0.173816  0.187638      1  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "513  0.034709 -0.057688  0.085145  0.059397  0.119146  0.114285      0  \n",
       "514 -0.011797 -0.064337  0.017005  0.087882  0.118566  0.137715      0  \n",
       "515 -0.024831 -0.072220 -0.001702  0.085262  0.091931  0.144309      0  \n",
       "516 -0.001430 -0.059596  0.059717  0.050933  0.101675  0.132865      0  \n",
       "517  0.015171 -0.053736  0.038425  0.062616  0.111214  0.115066      0  \n",
       "\n",
       "[518 rows x 840 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test dataset loading\n",
    "Test_csv_file_path = './data/TestSet/mRNA_sublocation_TestSet_NC-BERTdata.csv'\n",
    "Test_data= pd.read_csv(Test_csv_file_path)\n",
    "Test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2ef3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate sequence features and labels\n",
    "X_train = Training_data.drop(columns=['label']).values\n",
    "y_train = Training_data['label'].values\n",
    "\n",
    "X_test = Test_data.drop(columns=['label']).values\n",
    "y_test = Test_data['label'].values\n",
    "# the training data and test data are standardized\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fafa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "# Initialize PCA and set the number of principal components\n",
    "pca = PCA(n_components=72)\n",
    "# Fit PCA on the training data and transform the training data to its principal components\n",
    "X_train = pca.fit_transform(X_train)\n",
    "# Get the transformation matrix (principal components)\n",
    "transformation_matrix = pca.components_\n",
    "# Apply the same transformation matrix to the test data\n",
    "# This ensures the test data is transformed in the same way as the training data\n",
    "X_test = np.dot(X_test, transformation_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fffb8085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Search: 100%|███████████████████████████████████████████████████████████| 10/10 [10:59<00:00, 65.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# Random search was used, and the number of hyperparameters searched was defined\n",
    "num = 10\n",
    "# Define the hyperparameter search space\n",
    "n_estimators = [50,80,100, 200]\n",
    "max_depth = [5,10,15,20,25]\n",
    "\n",
    "# Hyperparameter tuning\n",
    "hyperparameter_space = list(product(n_estimators, max_depth))\n",
    "hyperparameters = [random.choice(hyperparameter_space) for i in range(num)]\n",
    "results = []\n",
    "best_acc = 0\n",
    "for hyperparameter in tqdm(hyperparameters, desc=\"Hyperparameter Search\"):\n",
    "    n_estimators, max_depth = hyperparameter\n",
    "   \n",
    "    val_accuracy_scores = []\n",
    "    val_precision_scores = []\n",
    "    val_recall_scores = []\n",
    "    val_f1_scores = []\n",
    "#     5-fold cross-validation    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train,y_train), 1):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth)\n",
    "        \n",
    "        clf.fit(X_train_fold,y_train_fold)\n",
    "        \n",
    "        val_predictions = clf.predict(X_val_fold)\n",
    "        val_accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "        val_precision = precision_score(y_val_fold, val_predictions)\n",
    "        val_recall = recall_score(y_val_fold, val_predictions)\n",
    "        val_f1 = f1_score(y_val_fold, val_predictions)\n",
    "\n",
    "#         Saving metrics        \n",
    "        val_accuracy_scores.append(val_accuracy)\n",
    "        val_precision_scores.append(val_precision)\n",
    "        val_recall_scores.append(val_recall)\n",
    "        val_f1_scores.append(val_f1)\n",
    "#   The average value of each metric was calculated   \n",
    "    val_ACC = np.mean(val_accuracy_scores)\n",
    "    val_Precision = np.mean(val_precision_scores)\n",
    "    val_Recall = np.mean(val_recall_scores)\n",
    "    val_F1 = np.mean(val_f1_scores)\n",
    "    \n",
    "\n",
    "# Independent testing    \n",
    "    clf.fit(X_train,y_train)\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,test_predictions)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "# Calculating test metrics\n",
    "    test_ACC = accuracy_score(y_test, test_predictions)\n",
    "    test_Precision = precision_score(y_test, test_predictions)\n",
    "    test_Recall = recall_score(y_test, test_predictions)\n",
    "    test_F1 = f1_score(y_test, test_predictions)\n",
    "    mcc = (TP * TN - FP * FN) / ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))**0.5\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_predictions, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"超参数组合\": hyperparameter,\n",
    "        \"val_ACC\": val_ACC,\n",
    "        \"val_Precision\": val_Precision,\n",
    "        \"val_Recall\": val_Recall,\n",
    "        \"val_F1\":val_F1,\n",
    "        \"test_ACC\":test_ACC,      \n",
    "        \"test_Precision\":test_Precision,\n",
    "        \"test_Recall\":test_Recall,\n",
    "        \"test_F1\":test_F1,\n",
    "        \"test_MCC\":mcc,\n",
    "        \"test_roc_auc\":roc_auc\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e36ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超参数: n_estimators, max_depth : (80, 20)\n",
      "val_ACC: 0.6793216308092866\n",
      "val_Precision: 0.6734720909296065\n",
      "val_Recall: 0.5108313568083684\n",
      "val_F1: 0.5807433505344998\n",
      "test_ACC: 0.7316602316602316\n",
      "test_Precision: 0.7329842931937173\n",
      "test_Recall: 0.6140350877192983\n",
      "test_F1: 0.6682577565632458\n",
      "test_MCC: 0.4508390169372627\n",
      "test_roc_auc: 0.7190865093768906\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (50, 10)\n",
      "val_ACC: 0.6818935180712915\n",
      "val_Precision: 0.6884911128654213\n",
      "val_Recall: 0.49109651523444625\n",
      "val_F1: 0.5729398590536078\n",
      "test_ACC: 0.7239382239382239\n",
      "test_Precision: 0.7514792899408284\n",
      "test_Recall: 0.5570175438596491\n",
      "test_F1: 0.6397984886649873\n",
      "test_MCC: 0.43642313365466134\n",
      "test_roc_auc: 0.7060949788263762\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (80, 15)\n",
      "val_ACC: 0.6861846735575396\n",
      "val_Precision: 0.6806990731546874\n",
      "val_Recall: 0.5246171623183118\n",
      "val_F1: 0.5920358650758836\n",
      "test_ACC: 0.7181467181467182\n",
      "test_Precision: 0.7180851063829787\n",
      "test_Recall: 0.5921052631578947\n",
      "test_F1: 0.6490384615384615\n",
      "test_MCC: 0.42259247602216526\n",
      "test_roc_auc: 0.7046733212341197\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (200, 10)\n",
      "val_ACC: 0.6838255385507087\n",
      "val_Precision: 0.6934215930554817\n",
      "val_Recall: 0.4896211153682418\n",
      "val_F1: 0.5737206096577889\n",
      "test_ACC: 0.7142857142857143\n",
      "test_Precision: 0.7352941176470589\n",
      "test_Recall: 0.5482456140350878\n",
      "test_F1: 0.628140703517588\n",
      "test_MCC: 0.4155523803764466\n",
      "test_roc_auc: 0.6965366001209922\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (80, 15)\n",
      "val_ACC: 0.68317877169498\n",
      "val_Precision: 0.6785829848355776\n",
      "val_Recall: 0.5167414705345739\n",
      "val_F1: 0.5865667408575989\n",
      "test_ACC: 0.7142857142857143\n",
      "test_Precision: 0.7325581395348837\n",
      "test_Recall: 0.5526315789473685\n",
      "test_F1: 0.6299999999999999\n",
      "test_MCC: 0.41530998646899075\n",
      "test_roc_auc: 0.697005444646098\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (50, 20)\n",
      "val_ACC: 0.6743885385185082\n",
      "val_Precision: 0.6628170625258323\n",
      "val_Recall: 0.5123067566745727\n",
      "val_F1: 0.57759630886327\n",
      "test_ACC: 0.7142857142857143\n",
      "test_Precision: 0.7127659574468085\n",
      "test_Recall: 0.5877192982456141\n",
      "test_F1: 0.6442307692307693\n",
      "test_MCC: 0.41450473115482317\n",
      "test_roc_auc: 0.700756200846945\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (100, 25)\n",
      "val_ACC: 0.6763226290198675\n",
      "val_Precision: 0.6719988065467508\n",
      "val_Recall: 0.5004889618682722\n",
      "val_F1: 0.5734631882080687\n",
      "test_ACC: 0.7123552123552124\n",
      "test_Precision: 0.7158469945355191\n",
      "test_Recall: 0.5745614035087719\n",
      "test_F1: 0.6374695863746959\n",
      "test_MCC: 0.4104795409181092\n",
      "test_roc_auc: 0.6976255293405929\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (100, 15)\n",
      "val_ACC: 0.6758886144193129\n",
      "val_Precision: 0.6679523315341902\n",
      "val_Recall: 0.5068831721705285\n",
      "val_F1: 0.5761556060708387\n",
      "test_ACC: 0.7065637065637066\n",
      "test_Precision: 0.7087912087912088\n",
      "test_Recall: 0.5657894736842105\n",
      "test_F1: 0.6292682926829268\n",
      "test_MCC: 0.3982858224920355\n",
      "test_roc_auc: 0.6915154264972777\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (50, 5)\n",
      "val_ACC: 0.6501531816237252\n",
      "val_Precision: 0.6922975510384639\n",
      "val_Recall: 0.35651888341543514\n",
      "val_F1: 0.46977371128828976\n",
      "test_ACC: 0.7046332046332047\n",
      "test_Precision: 0.7737226277372263\n",
      "test_Recall: 0.4649122807017544\n",
      "test_F1: 0.5808219178082192\n",
      "test_MCC: 0.4029449880773252\n",
      "test_roc_auc: 0.6790078644888081\n",
      "------------------------------------------------------------\n",
      "超参数: n_estimators, max_depth : (200, 5)\n",
      "val_ACC: 0.6606601529976217\n",
      "val_Precision: 0.7197404767906663\n",
      "val_Recall: 0.3599598613391717\n",
      "val_F1: 0.4797893654280051\n",
      "test_ACC: 0.6737451737451737\n",
      "test_Precision: 0.7478991596638656\n",
      "test_Recall: 0.39035087719298245\n",
      "test_F1: 0.5129682997118156\n",
      "test_MCC: 0.3385641581223352\n",
      "test_roc_auc: 0.6434513006654567\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# result ranking\n",
    "sorted_results = sorted(results, key=lambda x: x[\"test_ACC\"], reverse=True)\n",
    "for i,result in enumerate(sorted_results):\n",
    "    print(\"超参数: n_estimators, max_depth :\", result[\"超参数组合\"])\n",
    "    print(\"val_ACC:\", result[\"val_ACC\"])\n",
    "    print(\"val_Precision:\", result[\"val_Precision\"])\n",
    "    print(\"val_Recall:\", result[\"val_Recall\"])\n",
    "    print(\"val_F1:\", result[\"val_F1\"])\n",
    "    print(\"test_ACC:\", result[\"test_ACC\"])\n",
    "    print(\"test_Precision:\", result[\"test_Precision\"])\n",
    "    print(\"test_Recall:\", result[\"test_Recall\"])\n",
    "    print(\"test_F1:\", result[\"test_F1\"])\n",
    "    print(\"test_MCC:\", result[\"test_MCC\"])\n",
    "    print(\"test_roc_auc:\", result[\"test_roc_auc\"])\n",
    "    print(\"-\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d12ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
